model_params:
  model: finetune_vggresnet
  pretrained: "/media/ngxbac/DATA/logs_emotiw_temporal/feature_extractor/vggresnet/checkpoints/best.pth"
  n_class: 7

args:
  expdir: "src"
  logdir: &logdir "./logs/kerc"
  baselogdir: "./logs/kerc"

distributed_params:
  opt_level: O1

stages:

  state_params:
    main_metric: &reduce_metric accuracy01
    minimize_metric: False

  criterion_params:
    criterion: CrossEntropyLoss
#    criterion: LabelSmoothingCrossEntropy

  data_params:
    batch_size: 32
    num_workers: 4
    drop_last: False

    image_size: &image_size 224
    train_csv: "./preprocessing/csv/train_face.csv"
    valid_csv: "./preprocessing/csv/valid_face.csv"
    root: "/media/ngxbac/Bac/dataset/KERC/faces/"

  stage0:

    optimizer_params:
      optimizer: Adam
      lr: 0.0001
      weight_decay: 0.0001

    scheduler_params:
      scheduler: OneCycleLR
      num_steps: &num_epochs 15
      lr_range: [0.0005, 0.00001]
      warmup_steps: 5
      momentum_range: [0.85, 0.95]

    state_params:
      num_epochs: *num_epochs

    callbacks_params: &callback_params
      loss:
        callback: CriterionCallback
      optimizer:
        callback: OptimizerCallback
      accuracy:
        callback: AccuracyCallback
        accuracy_args: [1]
      scheduler:
        callback: SchedulerCallback
        reduce_metric: *reduce_metric
      saver:
        callback: CheckpointCallback


#  stage1:
#
#    optimizer_params:
#      optimizer: Adam
#      lr: 0.0001
#      weight_decay: 0.0001
#
#    scheduler_params:
#      scheduler: OneCycleLR
#      num_steps: &num_epochs 15
#      lr_range: [0.0005, 0.00001]
#      warmup_steps: 5
#      momentum_range: [0.85, 0.95]
#
#    state_params:
#      num_epochs: *num_epochs
#
#    callbacks_params: *callback_params